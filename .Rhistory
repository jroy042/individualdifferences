mod$b <- b <- c(runif(1,-2,2),runif(3,-1,1))
mod$ss <- ss <- c(runif(1,0,1),runif(3,0,0.5))
mod$os <- os <- rcorrmatrix(4)
Ls <- t(chol(os))
gs <- Ls %*% matrix(rnorm(S*4),4,S)
for(i in 1:4) gs[i,] <- gs[i,] * ss[i]
y <- as.vector(mod$mat %*% c(b,as.vector(gs)))
if(linear){
mod$se <- se <- runif(1,0,1)
mod$pext <- NA
y <- y + rnorm(N,0,se)
mod$frame$y <- scale(y)[,1]
mod$stan$y <- y
mod$mu <- mod$stan$mu <- mean(y)
mod$sdev <- mod$stan$sdev <- sd(y)
} else {
mod$se <- NA
mod$mu <- 0
mod$sdev <- 1
mod$pext <- mean(abs(y)>5)
mod$frame$y <- mod$stan$y <- rbinom(N,1,plogis(y))
}
return(mod)
}
### Fit single model with both lme4 and stan
single_model <- function(linear){
mod <- generate_model(linear)
if(linear){
possibleFail = tryCatch(m_lme4 <- summary(lmer(formula, mod$frame)), error = function(e) {mess_lme4=conditionMessage(e)})
m_stan <- sampling(object = gaustan, data = mod$stan, chains = 3,
pars = c(keep,"res"), control = list(adapt_delta = 0.99))
} else {
possibleFail = tryCatch(m_lme4 <- summary(glmer(formula, mod$frame, family = binomial)), error = function(e) {mess_lme4=conditionMessage(e)})
m_stan <- sampling(object = binstan, data = mod$stan, chains = 3,
pars = keep, control = list(adapt_delta = 0.99))
}
if(!inherits(possibleFail, "error")){
mess_lme4 <- m_lme4$optinfo$conv$lme4
if(!is.null(names(mess_lme4))){
mess_lme4 <- paste(mess_lme4$messages,collapse="; ")
mess_lme4 <- str_replace_all(mess_lme4,",","")
mess_lme4 <- str_replace_all(mess_lme4,"\n","")
} else {
mess_lme4 <- ""
}
vc <- data.frame(m_lme4$varcor)
theta <- m_lme4$optinfo$val
samp <- data.frame(do.call(rbind,
args=get_sampler_params(m_stan,inc_warmup=FALSE)))
nmtd <- sum(samp$treedepth__ > 10)
ndiv <- sum(samp$divergent__)
m_stan <- summary(m_stan,probs=c(.025,.975))$summary
rhat <- quantile(m_stan[,"Rhat"],c(0,.25,.5,.75,1))
neff <- quantile(m_stan[,"n_eff"],c(0,.25,.5,.75,1))
m_stan <- m_stan[,1]
if(mess_lme4 != "" | ndiv > 0 | as.numeric(rhat[5]) >= 1.1){
save(mod, file = paste(getwd(),"/unconverged_thread_",
thread,"_iteration_",b,"_linear_",linear,".rda",sep=""))
}
resb <- data.frame(
linear = linear, pext = mod$pext, N = mod$N, S = mod$S, L = mod$L,
balance = mod$balance, balance_ratio = mod$balance_ratio, mu = mod$mu, sdev = mod$sdev,
b0 = mod$b[1], b0_lme4 = m_lme4$coef[1,1] * mod$sdev + mod$mu, b0_stan = m_stan["coef[1]"],
b1 = mod$b[2], b1_lme4 = m_lme4$coef[2,1] * mod$sdev, b1_stan = m_stan["coef[2]"],
b2 = mod$b[3], b2_lme4 = m_lme4$coef[3,1] * mod$sdev, b2_stan = m_stan["coef[3]"],
b3 = mod$b[4], b3_lme4 = m_lme4$coef[4,1] * mod$sdev, b3_stan = m_stan["coef[4]"],
s0 = mod$ss[1], s0_lme4 = vc[1,5] * mod$sdev, s0_stan = m_stan["s0"],
s1 = mod$ss[2], s1_lme4 = vc[2,5] * mod$sdev, s1_stan = m_stan["s1"],
s2 = mod$ss[3], s2_lme4 = vc[3,5] * mod$sdev, s2_stan = m_stan["s2"],
s3 = mod$ss[4], s3_lme4 = vc[4,5] * mod$sdev, s3_stan = m_stan["s3"],
r01 = mod$os[2,1], r01_lme4 = vc[5,5], r01_stan = m_stan["r01"],
r02 = mod$os[3,1], r02_lme4 = vc[6,5], r02_stan = m_stan["r02"],
r03 = mod$os[4,1], r03_lme4 = vc[7,5], r03_stan = m_stan["r03"],
r12 = mod$os[3,2], r12_lme4 = vc[8,5], r12_stan = m_stan["r12"],
r13 = mod$os[4,2], r13_lme4 = vc[9,5], r13_stan = m_stan["r13"],
r23 = mod$os[4,3], r23_lme4 = vc[10,5], r23_stan = m_stan["r23"],
se = mod$se, se_lme4 = ifelse(linear,vc[11,5]*mod$sdev,NA), se_stan = ifelse(linear,m_stan["res"],NA),
mess_lme4, nmtd, ndiv,
rhat_min = rhat[1], rhat_q25 = rhat[2], rhat_med = rhat[3], rhat_q75 = rhat[4], rhat_max = rhat[5],
neff_min = neff[1], neff_q25 = neff[2], neff_med = neff[3], neff_q75 = neff[4], neff_max = neff[5])
for(i in 1:10) resb[,paste("theta",i,sep="_")] <- theta[i]
}
else{
samp <- data.frame(do.call(rbind,
args=get_sampler_params(m_stan,inc_warmup=FALSE)))
nmtd <- sum(samp$treedepth__ > 10)
ndiv <- sum(samp$divergent__)
m_stan <- summary(m_stan,probs=c(.025,.975))$summary
rhat <- quantile(m_stan[,"Rhat"],c(0,.25,.5,.75,1))
neff <- quantile(m_stan[,"n_eff"],c(0,.25,.5,.75,1))
m_stan <- m_stan[,1]
if(mess_lme4 != "" | ndiv > 0 | as.numeric(rhat[5]) >= 1.1){
save(mod, file = paste(getwd(),"/unconverged_thread_",
thread,"_iteration_",b,"_linear_",linear,".rda",sep=""))
}
resb <- data.frame(
linear = linear, pext = mod$pext, N = mod$N, S = mod$S, L = mod$L,
balance = mod$balance, balance_ratio = mod$balance_ratio, mu = mod$mu, sdev = mod$sdev,
b0 = mod$b[1], b0_lme4 = NA, b0_stan = m_stan["coef[1]"],
b1 = mod$b[2], b1_lme4 = NA, b1_stan = m_stan["coef[2]"],
b2 = mod$b[3], b2_lme4 = NA, b2_stan = m_stan["coef[3]"],
b3 = mod$b[4], b3_lme4 = NA, b3_stan = m_stan["coef[4]"],
s0 = mod$ss[1], s0_lme4 = NA, s0_stan = m_stan["s0"],
s1 = mod$ss[2], s1_lme4 = NA, s1_stan = m_stan["s1"],
s2 = mod$ss[3], s2_lme4 = NA, s2_stan = m_stan["s2"],
s3 = mod$ss[4], s3_lme4 = NA, s3_stan = m_stan["s3"],
r01 = mod$os[2,1], r01_lme4 = NA, r01_stan = m_stan["r01"],
r02 = mod$os[3,1], r02_lme4 = NA, r02_stan = m_stan["r02"],
r03 = mod$os[4,1], r03_lme4 = NA, r03_stan = m_stan["r03"],
r12 = mod$os[3,2], r12_lme4 = NA, r12_stan = m_stan["r12"],
r13 = mod$os[4,2], r13_lme4 = NA, r13_stan = m_stan["r13"],
r23 = mod$os[4,3], r23_lme4 = NA, r23_stan = m_stan["r23"],
se = mod$se, se_lme4 = NA, se_stan = ifelse(linear,m_stan["res"],NA),
mess_lme4, nmtd, ndiv,
rhat_min = rhat[1], rhat_q25 = rhat[2], rhat_med = rhat[3], rhat_q75 = rhat[4], rhat_max = rhat[5],
neff_min = neff[1], neff_q25 = neff[2], neff_med = neff[3], neff_q75 = neff[4], neff_max = neff[5])
}
return(resb)
}
## unpack arguments
B <- pardat[[1]]
thread <- pardat[[2]]
gaustan <- pardat[[3]]
binstan <- pardat[[4]]
### run B iterations of each of the 2 models based on H0 and output progress to thread-specific file
results <- NULL
progfile <- paste(getwd(),"/","imbalanced_sim_thread_",thread,".progress",sep="")
csvfile <- paste(getwd(),"/","imbalanced_sim_thread_",thread,".csv",sep="")
cat(paste(Sys.time(),"Starting Thread",thread),file=progfile,sep="\n",append=FALSE)
for(b in 1:B){  # Each iteration has 2 calls to single_model, one for each H0 condition
cat("\n",paste(Sys.time(),"Iteration",b,"/",B),file=progfile,sep="",append=TRUE)
results <- rbind(results,single_model(TRUE))
cat(" . ",file=progfile,sep="",append=TRUE)
results <- rbind(results,single_model(FALSE))
cat(" . ",file=progfile,sep="",append=TRUE)
write.csv(results,row.names=F,quote=F,file=csvfile)
}
cat("\n",paste(Sys.time(),"Finished Thread",thread),file=progfile,sep="",append=TRUE)
### return results
return(results)
}
{### Stan code
{	bincode <- "// Stan code for logistic regression simulation
// adapted from Kimball, Shantz, Eager, and Roy (2016)
data {
int<lower=2> N;  // number of observations
int<lower=2> S;  // number of subjects
int<lower=1> P;  // number of fixed effects
int<lower=1,upper=P> QS;  // number of subject effects
// sparse model matrix (CSR)
int<lower=1> nz;  // number of non-zero elements in x
vector[nz] x_w;  // non-zero elements in x
int x_v[nz];  // column indices for x_w
int x_u[N+1];  // row-start indices for x
int<lower=0,upper=1> y[N];  // binary response
}
transformed data {
int K;  // number of columns in x
int SF;  // first subject effect column in x
int SL;  // last subject effect column in x
K = P + S * QS;
SF = P + 1;
SL = P + S * QS;
}
parameters {
vector[P] beta;
matrix[QS,S] gamma_subj_raw;
vector<lower=0>[QS] sigma_subj;  // subject effect SDs
cholesky_factor_corr[QS] omega_subj_raw;
}
transformed parameters {
vector[K] coef;  // all coefficients
vector[N] y_hat;  // predicted log-odds
// transform fixed effects
coef[1:P] = 2 * beta;
// transform subject effects
coef[SF:SL]
= to_vector(rep_matrix(sigma_subj,S)
.* (omega_subj_raw * gamma_subj_raw));
// y_hat = x * coef
y_hat = csr_matrix_times_vector(N,K,x_w,x_v,x_u,coef);
}
model {
beta ~ normal(0,1);
to_vector(gamma_subj_raw) ~ normal(0,1);
sigma_subj ~ normal(0,1);
omega_subj_raw ~ lkj_corr_cholesky(2);
y ~ bernoulli_logit(y_hat);  // logistic model defined
}
generated quantities {
real<lower=0> s0;
real<lower=0> s1;
real<lower=0> s2;
real<lower=0> s3;
real<lower=-1,upper=1> r01;
real<lower=-1,upper=1> r02;
real<lower=-1,upper=1> r03;
real<lower=-1,upper=1> r12;
real<lower=-1,upper=1> r13;
real<lower=-1,upper=1> r23;
s0 = sigma_subj[1];
s1 = sigma_subj[2];
s2 = sigma_subj[3];
s3 = sigma_subj[4];
{
matrix[QS,QS] omega_subj;  // correlation in subject effects
omega_subj = tcrossprod(omega_subj_raw);
r01 = omega_subj[2,1];
r02 = omega_subj[3,1];
r03 = omega_subj[4,1];
r12 = omega_subj[3,2];
r13 = omega_subj[4,2];
r23 = omega_subj[4,3];
}
}
"
}
{	gaucode <- "// Stan code for linear regression simulation
// adapted from Kimball, Shantz, Eager, and Roy (2016)
data {
int<lower=2> N;  // number of observations
int<lower=2> S;  // number of subjects
int<lower=1> P;  // number of fixed effects
int<lower=1,upper=P> QS;  // number of subject effects
// sparse model matrix (CSR)
int<lower=1> nz;  // number of non-zero elements in x
vector[nz] x_w;  // non-zero elements in x
int x_v[nz];  // column indices for x_w
int x_u[N+1];  // row-start indices for x
vector[N] y;  // continuous response
real mu;  // mean(y)
real<lower=0> sdev;  // sd(y)
}
transformed data {
int K;  // number of columns in x
int SF;  // first subject effect column in x
int SL;  // last subject effect column in x
K = P + S * QS;
SF = P + 1;
SL = P + S * QS;
}
parameters {
vector[P] beta_raw;
real<lower=0> res_raw;
matrix[QS,S] gamma_subj_raw;
vector<lower=0>[QS] sigma_subj_raw;
cholesky_factor_corr[QS] omega_subj_raw;
}
transformed parameters {
vector[K] coef;  // all coefficients
real<lower=0> res;  // residual standard error
vector[N] y_hat;  // predicted log-odds
// transform fixed effects
coef[1:P] = beta_raw * 2 * sdev;
coef[1] = coef[1] + mu;
res = 0.5 * sdev * res_raw;
// transform subject effects
coef[SF:SL]
= to_vector((rep_matrix(sigma_subj_raw,S) * sdev)
.* (omega_subj_raw * gamma_subj_raw));
// y_hat = x * coef
y_hat = csr_matrix_times_vector(N,K,x_w,x_v,x_u,coef);
}
model {
beta_raw ~ normal(0,1);
res_raw ~ normal(0,1);
to_vector(gamma_subj_raw) ~ normal(0,1);
sigma_subj_raw ~ normal(0,1);
omega_subj_raw ~ lkj_corr_cholesky(2);
y ~ normal(y_hat,res);  // linear model defined
}
generated quantities {
real<lower=0> s0;
real<lower=0> s1;
real<lower=0> s2;
real<lower=0> s3;
real<lower=-1,upper=1> r01;
real<lower=-1,upper=1> r02;
real<lower=-1,upper=1> r03;
real<lower=-1,upper=1> r12;
real<lower=-1,upper=1> r13;
real<lower=-1,upper=1> r23;
s0 = sigma_subj_raw[1] * sdev;
s1 = sigma_subj_raw[2] * sdev;
s2 = sigma_subj_raw[3] * sdev;
s3 = sigma_subj_raw[4] * sdev;
{
matrix[QS,QS] omega_subj;  // correlation in subject effects
omega_subj = tcrossprod(omega_subj_raw);
r01 = omega_subj[2,1];
r02 = omega_subj[3,1];
r03 = omega_subj[4,1];
r12 = omega_subj[3,2];
r13 = omega_subj[4,2];
r23 = omega_subj[4,3];
}
}
"
}
}
require(rstan)
gaustan <- stan_model(model_name = "linear_sim", model_code = gaucode, save_dso = TRUE)
binstan <- stan_model(model_name = "logistic_sim", model_code = bincode, save_dso = TRUE)
if(threads==1){
options(mc.cores = parallel::detectCores())
results <- single_thread(list(B,threads,gaustan,binstan))
} else {
require(parallel)
cl = makeCluster(rep("localhost", threads))
# simulations per thread and thread number
left <- B %% threads
B <- rep(floor(B/threads),threads)
if(left>0) B[1:left] <- B[1:left] + 1
pardat <- list()
for(i in 1:threads) pardat[[i]] <- list(B[i],i,gaustan,binstan)
results <- parLapply(cl,pardat,single_thread)
stopCluster(cl)
results <- do.call(rbind,args=results)
}
return(results)
}
compare_lme4_stan_imbalanced(threads=16)
?parellel
??parellel
library(lme4)
library(visreg)
library(mgcv)
library(stringr)
library(tidyr)
library(dplyr)
simple_linear = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Linear/data/allLinearSims.csv",header=TRUE)
simple_logistic = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Logistic/data/alllogisticSims_fixed.csv",header=TRUE)
complex_sim = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Complex Linear and Logistic/data/imbalanced_sim_data_12_19_16.csv",header=TRUE)
simple_linear$conv_stan <- 1*(simple_linear$ndiv == 0 & simple_linear$rhat_max < 1.1)
simple_linear$conv_lme4 <- 1
simple_linear$grad_lme4 <- .002
mess <- simple_linear$conv_lme4[simple_linear$conv_lmer!=""]
messconv <- rep(1,length(mess))
messgrad <- rep(.002,length(mess))
for(i in c("negative","ratio","unable")){
messconv <- messconv * unlist(lapply(
str_locate_all(mess,i),function(x){ 1*(nrow(x) == 0) }))
}
checkgrad <- unlist(lapply(str_locate_all(
mess,"converge with max"),function(x){ nrow(x) > 0 }))
for(i in 1:length(mess)){
if(checkgrad[i]){
j <- str_split(mess[i],"converge with max")[[1]][2]
j <- substr(j,10,nchar(j))
j <- as.numeric(str_split(j," ")[[1]][1])
messgrad[i] <- j
}
}
messconv <- messconv * (messgrad < 0.01)
simple_linear$conv_lme4[simple_linear$mess_lme4!=""] <- messconv
simple_linear$grad_lme4[simple_linear$mess_lme4!=""] <- messgrad
## Yes, I know we need to put this in a function.
simple_logistic$conv_stan <- 1*(simple_logistic$ndiv == 0 & simple_logistic$rhat_max < 1.1)
simple_logistic$conv_lme4 <- 1
simple_logistic$grad_lme4 <- .002
mess <- simple_logistic$mess_lme4[simple_logistic$mess_lme4!=""]
messconv <- rep(1,length(mess))
messgrad <- rep(.002,length(mess))
for(i in c("negative","ratio","unable")){
messconv <- messconv * unlist(lapply(
str_locate_all(mess,i),function(x){ 1*(nrow(x) == 0) }))
}
checkgrad <- unlist(lapply(str_locate_all(
mess,"converge with max"),function(x){ nrow(x) > 0 }))
for(i in 1:length(mess)){
if(checkgrad[i]){
j <- str_split(mess[i],"converge with max")[[1]][2]
j <- substr(j,10,nchar(j))
j <- as.numeric(str_split(j," ")[[1]][1])
messgrad[i] <- j
}
}
messconv <- messconv * (messgrad < 0.01)
simple_logistic$conv_lme4[simple_logistic$mess_lme4!=""] <- messconv
simple_logistic$grad_lme4[simple_logistic$mess_lme4!=""] <- messgrad
lme4com = complex_sim[complex_sim$reg=="lme4",]
gam1 = gam(conv~fam+s(balance)+s(minvar)+s(S,k=5),data=lme4com,family="binomial")
vardf = cbind(simple_logistic$s0,simple_logistic$s1,simple_logistic$i0,simple_logistic$i1)
minvar<-apply(vardf,1,function(x)return(array(min(x))))
simple_logistic$minvar = minvar
glm1 = glm(conv_lme4~minvar,data=simple_logistic,family="binomial")
errordf = complex_sim  %>%
mutate(b0_error = sqrt((b0_pred - b0)^2),
b1_error = sqrt((b1_pred - b1)^2),
b2_error = sqrt((b2_pred -b2)^2),
b3_error = sqrt((b3_pred - b3)^2),
s0_error = sqrt((s0_pred - s0)^2),
s1_error = sqrt((s1_pred - s1)^2),
s2_error = sqrt((s2_pred -s2)^2),
s3_error = sqrt((s3_pred - s3)^2),
r01_error = sqrt((r01_pred - r01)^2),
r02_error = sqrt((r02_pred -r02)^2),
r03_error = sqrt((r03_pred - r03)^2),
r13_error = sqrt((r13_pred - r13)^2),
r12_error = sqrt((r12_pred -r12)^2),
r23_error = sqrt((r23_pred - r23)^2),
model_num = paste0("t",thread,"i",iteration,"f",fam,"r",reg)) %>%
gather(type,error,b0_error:r23_error) %>%
filter(conv==1)
error_gam = gam(error ~ type*fam*reg + s(balance),data=errordf)
library(lme4)
library(visreg)
library(mgcv)
library(stringr)
library(tidyr)
library(dplyr)
simple_linear = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Linear/data/allLinearSims.csv",header=TRUE)
simple_logistic = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Logistic/data/alllogisticSims_fixed.csv",header=TRUE)
complex_sim = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Complex Linear and Logistic/data/imbalanced_sim_data_12_19_16.csv",header=TRUE)
simple_logistic = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Logistic/data/simpleLogistic.csv",header=TRUE)
simple_logistic = read.csv("/data/Dropbox/current projects/Bayesian Models Lx/simulations/Results LSA 2017 Poster/Simple Logistic/data/simpleLogistic.csv",header=TRUE)
simple_linear$conv_stan <- 1*(simple_linear$ndiv == 0 & simple_linear$rhat_max < 1.1)
simple_linear$conv_lme4 <- 1
simple_linear$grad_lme4 <- .002
mess <- simple_linear$conv_lme4[simple_linear$conv_lmer!=""]
messconv <- rep(1,length(mess))
messgrad <- rep(.002,length(mess))
for(i in c("negative","ratio","unable")){
messconv <- messconv * unlist(lapply(
str_locate_all(mess,i),function(x){ 1*(nrow(x) == 0) }))
}
checkgrad <- unlist(lapply(str_locate_all(
mess,"converge with max"),function(x){ nrow(x) > 0 }))
for(i in 1:length(mess)){
if(checkgrad[i]){
j <- str_split(mess[i],"converge with max")[[1]][2]
j <- substr(j,10,nchar(j))
j <- as.numeric(str_split(j," ")[[1]][1])
messgrad[i] <- j
}
}
messconv <- messconv * (messgrad < 0.01)
simple_linear$conv_lme4[simple_linear$mess_lme4!=""] <- messconv
simple_linear$grad_lme4[simple_linear$mess_lme4!=""] <- messgrad
## Yes, I know we need to put this in a function.
simple_logistic$conv_stan <- 1*(simple_logistic$ndiv == 0 & simple_logistic$rhat_max < 1.1)
simple_logistic$conv_lme4 <- 1
simple_logistic$grad_lme4 <- .002
mess <- simple_logistic$mess_lme4[simple_logistic$mess_lme4!=""]
messconv <- rep(1,length(mess))
messgrad <- rep(.002,length(mess))
for(i in c("negative","ratio","unable")){
messconv <- messconv * unlist(lapply(
str_locate_all(mess,i),function(x){ 1*(nrow(x) == 0) }))
}
checkgrad <- unlist(lapply(str_locate_all(
mess,"converge with max"),function(x){ nrow(x) > 0 }))
for(i in 1:length(mess)){
if(checkgrad[i]){
j <- str_split(mess[i],"converge with max")[[1]][2]
j <- substr(j,10,nchar(j))
j <- as.numeric(str_split(j," ")[[1]][1])
messgrad[i] <- j
}
}
messconv <- messconv * (messgrad < 0.01)
simple_logistic$conv_lme4[simple_logistic$mess_lme4!=""] <- messconv
simple_logistic$grad_lme4[simple_logistic$mess_lme4!=""] <- messgrad
lme4com = complex_sim[complex_sim$reg=="lme4",]
gam1 = gam(conv~fam+s(balance)+s(minvar)+s(S,k=5),data=lme4com,family="binomial")
vardf = cbind(simple_logistic$s0,simple_logistic$s1,simple_logistic$i0,simple_logistic$i1)
minvar<-apply(vardf,1,function(x)return(array(min(x))))
simple_logistic$minvar = minvar
errordf = complex_sim  %>%
mutate(b0_error = sqrt((b0_pred - b0)^2),
b1_error = sqrt((b1_pred - b1)^2),
b2_error = sqrt((b2_pred -b2)^2),
b3_error = sqrt((b3_pred - b3)^2),
s0_error = sqrt((s0_pred - s0)^2),
s1_error = sqrt((s1_pred - s1)^2),
s2_error = sqrt((s2_pred -s2)^2),
s3_error = sqrt((s3_pred - s3)^2),
r01_error = sqrt((r01_pred - r01)^2),
r02_error = sqrt((r02_pred -r02)^2),
r03_error = sqrt((r03_pred - r03)^2),
r13_error = sqrt((r13_pred - r13)^2),
r12_error = sqrt((r12_pred -r12)^2),
r23_error = sqrt((r23_pred - r23)^2),
model_num = paste0("t",thread,"i",iteration,"f",fam,"r",reg)) %>%
gather(type,error,b0_error:r23_error) %>%
filter(conv==1)
gam1 = gam(conv~fam+s(balance)+s(minvar)+s(S,k=5),data=lme4com,family="binomial")
summary(gam1)
gam2 = gam(conv~fam+s(balance)+s(minvar)+s(L),data=lme4com,family="binomial")
summary(gam2)
glm1 = glm(conv_lme4~minvar,data=simple_logistic,family="binomial")
summary(glm1)
error_gam = gam(error ~ type*fam*reg + s(balance),data=errordf)
summary(error_gam)
require(mgcv)
require(visreg)
require(parallel)
require(irr)
totList = readRPT(dirR="/data/Dropbox/current papers/Active/Cole-Mahrt-Roy/Cole-Mahrt-Roy prosody modeling/data")
#totList = readRPT(dirR="/data/Dropbox/current papers/Active/Lab Phonology/Cole-Mahrt-Roy prosody modeling/data",cutT=FALSE)
list2env(totList ,.GlobalEnv)
setwd("/data/Dropbox/current papers/Active/Cole-Mahrt-Roy/LabPhon special issue (ETAP)/github/individualdifferences/")
source("1_readRPT.r")
require(mgcv)
require(visreg)
require(parallel)
require(irr)
totList = readRPT(dirR="/data/Dropbox/current papers/Active/Cole-Mahrt-Roy/Cole-Mahrt-Roy prosody modeling/data")
#totList = readRPT(dirR="/data/Dropbox/current papers/Active/Lab Phonology/Cole-Mahrt-Roy prosody modeling/data",cutT=FALSE)
list2env(totList ,.GlobalEnv)
table(labuslong$pos)
table(labuslong2$pos)
